{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIdODqrMFqnP8oQUUoYd4L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varun-beep/DeepLearning/blob/main/DL_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulLkoNB3qqmp",
        "outputId": "be410b4e-da8c-4e25-a46a-8968f136e7a1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (24.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (2.13.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.15.0 tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qEN9xw6q9JX",
        "outputId": "6c91355e-a3fc-44e6-8213-76a03556065b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BFAerTjmeGEe"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils import compute_class_weight\n",
        "import tensorflow_addons as tfa"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.regularizers import l1, l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils import compute_class_weight\n"
      ],
      "metadata": {
        "id": "r4z0kDxMtLu2"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/heart_disease_uci.csv\")"
      ],
      "metadata": {
        "id": "OvGOdGKMrmqD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['id'], errors='ignore')\n",
        "\n",
        "# Identify categorical columns\n",
        "categorical_cols = ['sex', 'cp', 'restecg', 'exang', 'slope', 'thal']\n",
        "\n",
        "# Handling missing values\n",
        "numerical_cols = ['trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
        "df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
        "df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].median())\n",
        "\n",
        "# Handling the 'dataset' column (contains city names like 'Cleveland')\n",
        "if 'dataset' in df.columns:\n",
        "    df = pd.get_dummies(df, columns=['dataset'], drop_first=True)  # One-Hot Encoding\n",
        "\n",
        "# One-Hot Encoding for categorical variables\n",
        "df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)\n",
        "\n",
        "# Standardizing numerical features\n",
        "scaler = StandardScaler()\n",
        "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "# Ensure all columns are numeric\n",
        "df = df.apply(pd.to_numeric)\n",
        "\n",
        "# Creating separate datasets for multi-class and binary classification\n",
        "df_multi_class = df.copy()\n",
        "df_binary_class = df.copy()\n",
        "df_binary_class['num'] = df_binary_class['num'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Splitting data\n",
        "X_multi = df_multi_class.drop(columns=['num'])\n",
        "y_multi = df_multi_class['num']\n",
        "X_bin = df_binary_class.drop(columns=['num'])\n",
        "y_bin = df_binary_class['num']\n",
        "\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_multi, y_multi, test_size=0.2, random_state=42)\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eti3UfBefkPG",
        "outputId": "3931181f-b974-4638-ae07-2e9e016c9eb6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-3a926154d414>:9: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create DFN model\n",
        "def create_dfn(activation='relu', optimizer='adam', reg=None, dropout_rate=0.0):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, activation=activation, input_shape=(X_train_bin.shape[1],), kernel_regularizer=reg))\n",
        "    for _ in range(4):\n",
        "        model.add(Dense(64, activation=activation, kernel_regularizer=reg))\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "WCy65HRbf4MY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate models\n",
        "activations = ['relu', 'tanh', 'sigmoid']\n",
        "optimizers = ['adam', 'sgd']\n",
        "regularizations = [None, l1(0.01), l2(0.01)]\n",
        "dropout_rates = [0.0, 0.3]\n",
        "\n",
        "results = []\n",
        "\n",
        "for activation in activations:\n",
        "    for optimizer in optimizers:\n",
        "        for reg in regularizations:\n",
        "            for dropout in dropout_rates:\n",
        "                model = create_dfn(activation=activation, optimizer=optimizer, reg=reg, dropout_rate=dropout)\n",
        "                model.fit(X_train_bin, y_train_bin, epochs=50, batch_size=32, verbose=0, validation_split=0.2)\n",
        "                y_pred = (model.predict(X_test_bin) > 0.5).astype(int)\n",
        "\n",
        "                accuracy = accuracy_score(y_test_bin, y_pred)\n",
        "                precision = precision_score(y_test_bin, y_pred)\n",
        "                recall = recall_score(y_test_bin, y_pred)\n",
        "                f1 = f1_score(y_test_bin, y_pred)\n",
        "\n",
        "                results.append({\n",
        "                    'Activation': activation,\n",
        "                    'Optimizer': optimizer,\n",
        "                    'Regularization': reg,\n",
        "                    'Dropout': dropout,\n",
        "                    'Accuracy': accuracy,\n",
        "                    'Precision': precision,\n",
        "                    'Recall': recall,\n",
        "                    'F1-score': f1\n",
        "                })\n",
        "\n",
        "# Convert results to DataFrame and analyze\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.sort_values(by='Accuracy', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "zhtu9GlngBzn",
        "outputId": "d12833e5-091f-47d9-9611-7e5a3cb15876"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-054ff8886de7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdropout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdropout_rates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_bin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_bin\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_binary_class['num'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq5HnbfOgRTv",
        "outputId": "b55c3955-71f5-486e-eb22-1013993c7a2d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num\n",
            "1    509\n",
            "0    411\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier().fit(X_train_bin, y_train_bin)\n",
        "feature_importances = pd.Series(rf.feature_importances_, index=X_train_bin.columns).sort_values(ascending=False)\n",
        "print(feature_importances)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbiKEsJ3ldv7",
        "outputId": "204af8d8-6a31-4c16-8fd6-5fcdb383f56e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thalch                      0.120321\n",
            "chol                        0.119524\n",
            "oldpeak                     0.114796\n",
            "age                         0.093955\n",
            "exang_True                  0.084142\n",
            "trestbps                    0.077935\n",
            "cp_atypical angina          0.065416\n",
            "sex_Male                    0.058621\n",
            "dataset_Switzerland         0.034699\n",
            "cp_non-anginal              0.031576\n",
            "ca                          0.028450\n",
            "thal_normal                 0.027553\n",
            "fbs                         0.025181\n",
            "dataset_VA Long Beach       0.018176\n",
            "slope_upsloping             0.017384\n",
            "restecg_normal              0.015911\n",
            "dataset_Hungary             0.015745\n",
            "thal_reversable defect      0.013767\n",
            "cp_typical angina           0.013607\n",
            "restecg_st-t abnormality    0.011724\n",
            "slope_flat                  0.011519\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure no NaN values before SMOTE\n",
        "if df.isnull().sum().sum() > 0:\n",
        "    df = df.fillna(df.median())\n",
        "\n",
        "# Handling class imbalance\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_bin), y=y_train_bin)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Re-check for NaNs before applying SMOTE\n",
        "X_train_bin = X_train_bin.dropna()\n",
        "y_train_bin = y_train_bin.loc[X_train_bin.index]\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_bin, y_train_bin = smote.fit_resample(X_train_bin, y_train_bin)"
      ],
      "metadata": {
        "id": "wq-umXENouvq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['id'], errors='ignore')\n",
        "\n",
        "# Handling missing values with improved column checks\n",
        "categorical_cols = ['sex', 'cp', 'restecg', 'exang', 'slope', 'thal']\n",
        "numerical_cols = ['trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
        "\n",
        "available_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
        "available_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
        "\n",
        "if available_categorical_cols:\n",
        "    df[available_categorical_cols] = df[available_categorical_cols].fillna(df[available_categorical_cols].mode().iloc[0])\n",
        "\n",
        "if available_numerical_cols:\n",
        "    df[available_numerical_cols] = df[available_numerical_cols].fillna(df[available_numerical_cols].median())\n",
        "\n",
        "# One-Hot Encoding for categorical variables\n",
        "df = pd.get_dummies(df, columns=available_categorical_cols, drop_first=True)\n",
        "\n",
        "# Standardizing numerical features\n",
        "scaler = StandardScaler()\n",
        "if available_numerical_cols:\n",
        "    df[available_numerical_cols] = scaler.fit_transform(df[available_numerical_cols])\n",
        "\n",
        "# Ensure all columns are numeric\n",
        "df = df.apply(pd.to_numeric)\n",
        "\n",
        "# Removing less relevant categorical features\n",
        "df = df.drop(columns=['dataset_Switzerland', 'dataset_Hungary', 'dataset_VA Long Beach'], errors='ignore')\n",
        "\n",
        "# Creating separate datasets for multi-class and binary classification\n",
        "df_multi_class = df.copy()\n",
        "df_binary_class = df.copy()\n",
        "df_binary_class['num'] = df_binary_class['num'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Splitting data\n",
        "X_multi = df_multi_class.drop(columns=['num'])\n",
        "y_multi = df_multi_class['num']\n",
        "X_bin = df_binary_class.drop(columns=['num'])\n",
        "y_bin = df_binary_class['num']\n",
        "\n",
        "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(X_multi, y_multi, test_size=0.2, random_state=42)\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handling class imbalance\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_bin), y=y_train_bin)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_bin, y_train_bin = smote.fit_resample(X_train_bin, y_train_bin)"
      ],
      "metadata": {
        "id": "o2EVJFf5l8V-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create DFN model\n",
        "def create_dfn(activation='relu', optimizer='adam', reg=None, dropout_rate=0.0):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train_bin.shape[1],)))\n",
        "    model.add(Dense(64, activation=activation, kernel_regularizer=reg))\n",
        "    for _ in range(4):\n",
        "        model.add(Dense(64, activation=activation, kernel_regularizer=reg))\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "U8EafupCm6Qj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to DataFrame and analyze\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.sort_values(by='Accuracy', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "6nBZ8iX8o6Sk",
        "outputId": "8770e531-1c88-407e-ab77-32747b0f3697"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Accuracy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-5254d02746d6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert results to DataFrame and analyze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36msort_values\u001b[0;34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[0m\n\u001b[1;32m   7187\u001b[0m             \u001b[0;31m# len(by) == 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7189\u001b[0;31m             \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7191\u001b[0m             \u001b[0;31m# need to rewrap column in Series to apply key function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = results_df.sort_values(by=results_df.columns[0], ascending=False)  # Use first column as a fallback\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "8FBzmDLctmMm",
        "outputId": "246a8568-20e3-49ce-e64d-011bab51ac5a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 0 with size 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1017\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: range object index out of range",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-46dc63fc9d2c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mby\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use first column as a fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1018\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m                 raise IndexError(\n\u001b[0m\u001b[1;32m   1021\u001b[0m                     \u001b[0;34mf\"index {key} is out of bounds for axis 0 with size {len(self)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 ) from err\n",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model is performing poorlyâ€”accuracy is stuck at 40.76%, and precision, recall, and F1-score are all 0.0, which means the model isn't predicting the positive class at all."
      ],
      "metadata": {
        "id": "zxLbdegZpkdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Addressing class imbalance differently by trying class weights instead of SMOTE\n",
        "class_weights_bin = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_bin), y=y_train_bin)\n",
        "class_weights_bin = {i: class_weights_bin[i] for i in range(len(class_weights_bin))}\n",
        "\n",
        "# Modifying the DFN architecture: Increasing the number of neurons and adding Batch Normalization\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "def create_dfn_v2(activation='relu', optimizer='adam', reg=None, dropout_rate=0.0):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(X_train_bin.shape[1],)))\n",
        "    model.add(Dense(128, activation=activation, kernel_regularizer=reg))\n",
        "    model.add(BatchNormalization())\n",
        "    for _ in range(4):\n",
        "        model.add(Dense(128, activation=activation, kernel_regularizer=reg))\n",
        "        model.add(BatchNormalization())\n",
        "        if dropout_rate > 0:\n",
        "            model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Changing loss function to account for class imbalance\n",
        "model.compile(optimizer='adam', loss=tf.keras.losses.BinaryFocalCrossentropy(), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "amz12d3vo67E",
        "outputId": "86b40ad5-2c9a-49b5-8cb1-a0868ac1463c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-4152f693d6b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Changing loss function to account for class imbalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryFocalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert results to DataFrame and analyze\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.sort_values(by='Accuracy', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvhO5UOlqTRa",
        "outputId": "318fbb27-0c9d-484f-9d57-5a728a2ad231"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Activation Optimizer                                     Regularization  \\\n",
            "0        relu      adam                                               None   \n",
            "1        relu      adam                                               None   \n",
            "20       tanh       sgd  <keras.src.regularizers.regularizers.L1 object...   \n",
            "21       tanh       sgd  <keras.src.regularizers.regularizers.L1 object...   \n",
            "22       tanh       sgd  <keras.src.regularizers.regularizers.L2 object...   \n",
            "23       tanh       sgd  <keras.src.regularizers.regularizers.L2 object...   \n",
            "24    sigmoid      adam                                               None   \n",
            "25    sigmoid      adam                                               None   \n",
            "26    sigmoid      adam  <keras.src.regularizers.regularizers.L1 object...   \n",
            "27    sigmoid      adam  <keras.src.regularizers.regularizers.L1 object...   \n",
            "28    sigmoid      adam  <keras.src.regularizers.regularizers.L2 object...   \n",
            "29    sigmoid      adam  <keras.src.regularizers.regularizers.L2 object...   \n",
            "30    sigmoid       sgd                                               None   \n",
            "31    sigmoid       sgd                                               None   \n",
            "32    sigmoid       sgd  <keras.src.regularizers.regularizers.L1 object...   \n",
            "33    sigmoid       sgd  <keras.src.regularizers.regularizers.L1 object...   \n",
            "34    sigmoid       sgd  <keras.src.regularizers.regularizers.L2 object...   \n",
            "19       tanh       sgd                                               None   \n",
            "18       tanh       sgd                                               None   \n",
            "17       tanh      adam  <keras.src.regularizers.regularizers.L2 object...   \n",
            "8        relu       sgd  <keras.src.regularizers.regularizers.L1 object...   \n",
            "2        relu      adam  <keras.src.regularizers.regularizers.L1 object...   \n",
            "3        relu      adam  <keras.src.regularizers.regularizers.L1 object...   \n",
            "4        relu      adam  <keras.src.regularizers.regularizers.L2 object...   \n",
            "5        relu      adam  <keras.src.regularizers.regularizers.L2 object...   \n",
            "6        relu       sgd                                               None   \n",
            "7        relu       sgd                                               None   \n",
            "9        relu       sgd  <keras.src.regularizers.regularizers.L1 object...   \n",
            "16       tanh      adam  <keras.src.regularizers.regularizers.L2 object...   \n",
            "10       relu       sgd  <keras.src.regularizers.regularizers.L2 object...   \n",
            "11       relu       sgd  <keras.src.regularizers.regularizers.L2 object...   \n",
            "12       tanh      adam                                               None   \n",
            "13       tanh      adam                                               None   \n",
            "14       tanh      adam  <keras.src.regularizers.regularizers.L1 object...   \n",
            "15       tanh      adam  <keras.src.regularizers.regularizers.L1 object...   \n",
            "35    sigmoid       sgd  <keras.src.regularizers.regularizers.L2 object...   \n",
            "\n",
            "    Dropout  Accuracy  Precision  Recall  F1-score  \n",
            "0       0.0  0.407609        0.0     0.0       0.0  \n",
            "1       0.3  0.407609        0.0     0.0       0.0  \n",
            "20      0.0  0.407609        0.0     0.0       0.0  \n",
            "21      0.3  0.407609        0.0     0.0       0.0  \n",
            "22      0.0  0.407609        0.0     0.0       0.0  \n",
            "23      0.3  0.407609        0.0     0.0       0.0  \n",
            "24      0.0  0.407609        0.0     0.0       0.0  \n",
            "25      0.3  0.407609        0.0     0.0       0.0  \n",
            "26      0.0  0.407609        0.0     0.0       0.0  \n",
            "27      0.3  0.407609        0.0     0.0       0.0  \n",
            "28      0.0  0.407609        0.0     0.0       0.0  \n",
            "29      0.3  0.407609        0.0     0.0       0.0  \n",
            "30      0.0  0.407609        0.0     0.0       0.0  \n",
            "31      0.3  0.407609        0.0     0.0       0.0  \n",
            "32      0.0  0.407609        0.0     0.0       0.0  \n",
            "33      0.3  0.407609        0.0     0.0       0.0  \n",
            "34      0.0  0.407609        0.0     0.0       0.0  \n",
            "19      0.3  0.407609        0.0     0.0       0.0  \n",
            "18      0.0  0.407609        0.0     0.0       0.0  \n",
            "17      0.3  0.407609        0.0     0.0       0.0  \n",
            "8       0.0  0.407609        0.0     0.0       0.0  \n",
            "2       0.0  0.407609        0.0     0.0       0.0  \n",
            "3       0.3  0.407609        0.0     0.0       0.0  \n",
            "4       0.0  0.407609        0.0     0.0       0.0  \n",
            "5       0.3  0.407609        0.0     0.0       0.0  \n",
            "6       0.0  0.407609        0.0     0.0       0.0  \n",
            "7       0.3  0.407609        0.0     0.0       0.0  \n",
            "9       0.3  0.407609        0.0     0.0       0.0  \n",
            "16      0.0  0.407609        0.0     0.0       0.0  \n",
            "10      0.0  0.407609        0.0     0.0       0.0  \n",
            "11      0.3  0.407609        0.0     0.0       0.0  \n",
            "12      0.0  0.407609        0.0     0.0       0.0  \n",
            "13      0.3  0.407609        0.0     0.0       0.0  \n",
            "14      0.0  0.407609        0.0     0.0       0.0  \n",
            "15      0.3  0.407609        0.0     0.0       0.0  \n",
            "35      0.3  0.407609        0.0     0.0       0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam, AdamW, RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "J-7Dvstaqj09"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to float32\n",
        "y_train_bin = y_train_bin.astype(np.float32)\n",
        "y_test_bin = y_test_bin.astype(np.float32)\n",
        "\n",
        "# Convert features to float32\n",
        "X_train_bin = X_train_bin.astype(np.float32)\n",
        "X_test_bin = X_test_bin.astype(np.float32)\n"
      ],
      "metadata": {
        "id": "7o-dUjuuuySK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['id'], errors='ignore')\n",
        "\n",
        "# Handling missing values\n",
        "categorical_cols = ['sex', 'cp', 'restecg', 'exang', 'slope', 'thal']\n",
        "numerical_cols = ['trestbps', 'chol', 'thalach', 'oldpeak', 'ca']\n",
        "\n",
        "available_categorical_cols = [col for col in categorical_cols if col in df.columns]\n",
        "available_numerical_cols = [col for col in numerical_cols if col in df.columns]\n",
        "\n",
        "if available_categorical_cols:\n",
        "    df[available_categorical_cols] = df[available_categorical_cols].fillna(df[available_categorical_cols].mode().iloc[0])\n",
        "\n",
        "if available_numerical_cols:\n",
        "    df[available_numerical_cols] = df[available_numerical_cols].fillna(df[available_numerical_cols].median())\n",
        "\n",
        "# One-Hot Encoding for categorical variables\n",
        "df = pd.get_dummies(df, columns=available_categorical_cols, drop_first=True)\n",
        "\n",
        "# Standardizing numerical features\n",
        "scaler = StandardScaler()\n",
        "if available_numerical_cols:\n",
        "    df[available_numerical_cols] = scaler.fit_transform(df[available_numerical_cols])\n",
        "\n",
        "# Convert all columns to numeric\n",
        "df = df.apply(pd.to_numeric)\n",
        "\n",
        "# Binary Classification Dataset\n",
        "df_binary = df.copy()\n",
        "df_binary['num'] = df_binary['num'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# Multi-Class Dataset (if applicable)\n",
        "df_multi = df.copy()\n",
        "\n",
        "# Splitting Binary Data\n",
        "X_bin = df_binary.drop(columns=['num'])\n",
        "y_bin = df_binary['num']\n",
        "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(X_bin, y_bin, test_size=0.2, random_state=42)\n",
        "\n",
        "# Handle Class Imbalance using SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "X_train_bin, y_train_bin = smote.fit_resample(X_train_bin, y_train_bin)"
      ],
      "metadata": {
        "id": "KvSDxAbCu0ew"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute Class Weights\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_bin), y=y_train_bin.ravel())\n",
        "class_weights = {int(cls): weight for cls, weight in zip(np.unique(y_train_bin), class_weights)}"
      ],
      "metadata": {
        "id": "kwbWzrEmwE7t"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Ensure y_train_bin is a 1D NumPy array of integers\n",
        "y_train_bin = np.array(y_train_bin).flatten().astype(int)\n",
        "y_test_bin = np.array(y_test_bin).flatten().astype(int)\n",
        "\n",
        "# Compute Class Weights (Fixing Unhashable Type Error)\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight=\"balanced\",\n",
        "    classes=np.unique(y_train_bin),\n",
        "    y=y_train_bin.tolist()  # Convert to list\n",
        ")\n",
        "\n",
        "# Convert to dictionary format\n",
        "class_weights = {cls: weight for cls, weight in zip(np.unique(y_train_bin), class_weights)}\n",
        "\n",
        "# Print class weights\n",
        "print(\"Class Weights:\", class_weights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CKng0TAwPYd",
        "outputId": "6d573f72-0779-4203-8290-1ad946a9d9b4"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: {0: 1.0, 1: 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Binary Labels Sample:\", y_train_bin[:10])\n",
        "print(\"Multi-Class Labels Sample:\", y_train_multi[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piD6CbtmxLQ_",
        "outputId": "0798806c-8f12-4085-96c0-056e412a0813"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Binary Labels Sample: [[1.]\n",
            " [0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [1.]]\n",
            "Multi-Class Labels Sample: 880    4\n",
            "457    0\n",
            "797    3\n",
            "25     0\n",
            "84     0\n",
            "10     0\n",
            "346    0\n",
            "548    1\n",
            "636    2\n",
            "594    1\n",
            "Name: num, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train_bin Shape:\", X_train_bin.shape)\n",
        "print(\"y_train_bin Shape:\", y_train_bin.shape)\n",
        "print(\"X_train_multi Shape:\", X_train_multi.shape)\n",
        "print(\"y_train_multi Shape:\", y_train_multi.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IuDvGDmxTVs",
        "outputId": "7a25c0f8-9e3f-4f8a-ce9e-4b3425df9145"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_bin Shape: (800, 18)\n",
            "y_train_bin Shape: (800, 1)\n",
            "X_train_multi Shape: (736, 18)\n",
            "y_train_multi Shape: (736,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Ensure y_train_bin is 1D\n",
        "y_train_bin_1d = y_train_bin.ravel()\n",
        "\n",
        "# Compute Class Weights\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_bin_1d), y=y_train_bin_1d)\n",
        "class_weights = {int(cls): weight for cls, weight in zip(np.unique(y_train_bin_1d), class_weights)}\n",
        "\n",
        "print(\"Computed Class Weights:\", class_weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZMoCY2BxddR",
        "outputId": "ea22a652-6fb2-41d5-b726-d44b5fdc5a8d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Class Weights: {0: 1.0, 1: 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Convert y_train_multi to categorical\n",
        "num_classes = len(np.unique(y_train_multi))\n",
        "y_train_multi_encoded = to_categorical(y_train_multi, num_classes=num_classes)\n",
        "y_test_multi_encoded = to_categorical(y_test_multi, num_classes=num_classes)\n",
        "\n",
        "print(\"Shape after encoding:\", y_train_multi_encoded.shape)  # Should be (736, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF3WLWPGxl0_",
        "outputId": "14dac269-7a3e-423d-e968-842c03c3591f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape after encoding: (736, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_bin = scaler.fit_transform(X_train_bin)\n",
        "X_test_bin = scaler.transform(X_test_bin)\n",
        "\n",
        "X_train_multi = scaler.fit_transform(X_train_multi)\n",
        "X_test_multi = scaler.transform(X_test_multi)"
      ],
      "metadata": {
        "id": "2Vyh1L1wxtOr"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Binary Classification Model"
      ],
      "metadata": {
        "id": "4xFYVDnuyAHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Binary Classification Model\n",
        "binary_model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train_bin.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification\n",
        "])\n",
        "\n",
        "binary_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history_bin = binary_model.fit(X_train_bin, y_train_bin, epochs=50, batch_size=32, validation_data=(X_test_bin, y_test_bin))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9ArbzSQun-t",
        "outputId": "eb763206-0ed3-4c30-a6ca-ecb281859b51"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 4s 25ms/step - loss: 0.7109 - accuracy: 0.5350 - val_loss: 0.5788 - val_accuracy: 0.7174\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.5378 - accuracy: 0.7375 - val_loss: 0.4809 - val_accuracy: 0.8098\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.7837 - val_loss: 0.4285 - val_accuracy: 0.8370\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4637 - accuracy: 0.7987 - val_loss: 0.4117 - val_accuracy: 0.8370\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.4338 - accuracy: 0.8138 - val_loss: 0.4103 - val_accuracy: 0.8261\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.4104 - accuracy: 0.8225 - val_loss: 0.4087 - val_accuracy: 0.8207\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3823 - accuracy: 0.8375 - val_loss: 0.4045 - val_accuracy: 0.8207\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4000 - accuracy: 0.8300 - val_loss: 0.4094 - val_accuracy: 0.8152\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 0s 7ms/step - loss: 0.3822 - accuracy: 0.8500 - val_loss: 0.4016 - val_accuracy: 0.8152\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3875 - accuracy: 0.8325 - val_loss: 0.4036 - val_accuracy: 0.8261\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3772 - accuracy: 0.8512 - val_loss: 0.4120 - val_accuracy: 0.8207\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8487 - val_loss: 0.4003 - val_accuracy: 0.8152\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3616 - accuracy: 0.8500 - val_loss: 0.4012 - val_accuracy: 0.8261\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3655 - accuracy: 0.8550 - val_loss: 0.4114 - val_accuracy: 0.8207\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8525 - val_loss: 0.4009 - val_accuracy: 0.8261\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3731 - accuracy: 0.8462 - val_loss: 0.4014 - val_accuracy: 0.8315\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8562 - val_loss: 0.4093 - val_accuracy: 0.8207\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3539 - accuracy: 0.8537 - val_loss: 0.4027 - val_accuracy: 0.8261\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8687 - val_loss: 0.4023 - val_accuracy: 0.8315\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3515 - accuracy: 0.8525 - val_loss: 0.3998 - val_accuracy: 0.8370\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8600 - val_loss: 0.4044 - val_accuracy: 0.8315\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3385 - accuracy: 0.8637 - val_loss: 0.4094 - val_accuracy: 0.8261\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8700 - val_loss: 0.4047 - val_accuracy: 0.8315\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8575 - val_loss: 0.4018 - val_accuracy: 0.8315\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8475 - val_loss: 0.4019 - val_accuracy: 0.8315\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8763 - val_loss: 0.4055 - val_accuracy: 0.8261\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3285 - accuracy: 0.8562 - val_loss: 0.4059 - val_accuracy: 0.8261\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3220 - accuracy: 0.8700 - val_loss: 0.3990 - val_accuracy: 0.8315\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8675 - val_loss: 0.3992 - val_accuracy: 0.8315\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3293 - accuracy: 0.8662 - val_loss: 0.4003 - val_accuracy: 0.8370\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8763 - val_loss: 0.3992 - val_accuracy: 0.8370\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3166 - accuracy: 0.8637 - val_loss: 0.4024 - val_accuracy: 0.8315\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8587 - val_loss: 0.4071 - val_accuracy: 0.8261\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8625 - val_loss: 0.4026 - val_accuracy: 0.8261\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8712 - val_loss: 0.3967 - val_accuracy: 0.8315\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3149 - accuracy: 0.8737 - val_loss: 0.3981 - val_accuracy: 0.8261\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8750 - val_loss: 0.3980 - val_accuracy: 0.8315\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3195 - accuracy: 0.8662 - val_loss: 0.3940 - val_accuracy: 0.8370\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3210 - accuracy: 0.8687 - val_loss: 0.3967 - val_accuracy: 0.8370\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.8875 - val_loss: 0.4005 - val_accuracy: 0.8370\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.8737 - val_loss: 0.4008 - val_accuracy: 0.8315\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8775 - val_loss: 0.4037 - val_accuracy: 0.8370\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2969 - accuracy: 0.8863 - val_loss: 0.4052 - val_accuracy: 0.8370\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8725 - val_loss: 0.4013 - val_accuracy: 0.8424\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 0.2972 - accuracy: 0.8737 - val_loss: 0.4154 - val_accuracy: 0.8315\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.8850 - val_loss: 0.4124 - val_accuracy: 0.8424\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2989 - accuracy: 0.8775 - val_loss: 0.4047 - val_accuracy: 0.8315\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.2881 - accuracy: 0.8963 - val_loss: 0.4107 - val_accuracy: 0.8261\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 0s 5ms/step - loss: 0.3022 - accuracy: 0.8763 - val_loss: 0.4126 - val_accuracy: 0.8315\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.3049 - accuracy: 0.8800 - val_loss: 0.4059 - val_accuracy: 0.8370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Class Classification Model"
      ],
      "metadata": {
        "id": "R_3KCe12yLMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-Class Classification Model\n",
        "multi_model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_multi.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')  # Softmax for multi-class classification\n",
        "])\n",
        "\n",
        "multi_model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history_multi = multi_model.fit(X_train_multi, y_train_multi_encoded, epochs=50, batch_size=32, validation_data=(X_test_multi, y_test_multi_encoded))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFBR-n1wyFPI",
        "outputId": "8b5a829f-45b3-4d8a-a130-d1cd19ff5d4d"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "23/23 [==============================] - 2s 21ms/step - loss: 1.4555 - accuracy: 0.3845 - val_loss: 1.2657 - val_accuracy: 0.4891\n",
            "Epoch 2/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.1778 - accuracy: 0.5408 - val_loss: 1.1344 - val_accuracy: 0.5380\n",
            "Epoch 3/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.0930 - accuracy: 0.5543 - val_loss: 1.0743 - val_accuracy: 0.5326\n",
            "Epoch 4/50\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 1.0247 - accuracy: 0.5897 - val_loss: 1.0519 - val_accuracy: 0.5217\n",
            "Epoch 5/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 1.0004 - accuracy: 0.6073 - val_loss: 1.0468 - val_accuracy: 0.5272\n",
            "Epoch 6/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9635 - accuracy: 0.6196 - val_loss: 1.0500 - val_accuracy: 0.5435\n",
            "Epoch 7/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9640 - accuracy: 0.6033 - val_loss: 1.0516 - val_accuracy: 0.5489\n",
            "Epoch 8/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9720 - accuracy: 0.5965 - val_loss: 1.0529 - val_accuracy: 0.5489\n",
            "Epoch 9/50\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.9531 - accuracy: 0.6332 - val_loss: 1.0553 - val_accuracy: 0.5543\n",
            "Epoch 10/50\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.9276 - accuracy: 0.6277 - val_loss: 1.0613 - val_accuracy: 0.5489\n",
            "Epoch 11/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.9146 - accuracy: 0.6386 - val_loss: 1.0674 - val_accuracy: 0.5489\n",
            "Epoch 12/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8990 - accuracy: 0.6318 - val_loss: 1.0673 - val_accuracy: 0.5380\n",
            "Epoch 13/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.8950 - accuracy: 0.6304 - val_loss: 1.0674 - val_accuracy: 0.5598\n",
            "Epoch 14/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.9012 - accuracy: 0.6372 - val_loss: 1.0777 - val_accuracy: 0.5489\n",
            "Epoch 15/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8841 - accuracy: 0.6440 - val_loss: 1.0689 - val_accuracy: 0.5489\n",
            "Epoch 16/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8599 - accuracy: 0.6413 - val_loss: 1.0704 - val_accuracy: 0.5435\n",
            "Epoch 17/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8819 - accuracy: 0.6277 - val_loss: 1.0766 - val_accuracy: 0.5489\n",
            "Epoch 18/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8759 - accuracy: 0.6372 - val_loss: 1.0766 - val_accuracy: 0.5435\n",
            "Epoch 19/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8413 - accuracy: 0.6617 - val_loss: 1.0660 - val_accuracy: 0.5543\n",
            "Epoch 20/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8358 - accuracy: 0.6291 - val_loss: 1.0824 - val_accuracy: 0.5489\n",
            "Epoch 21/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8276 - accuracy: 0.6726 - val_loss: 1.0701 - val_accuracy: 0.5489\n",
            "Epoch 22/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8293 - accuracy: 0.6522 - val_loss: 1.0805 - val_accuracy: 0.5598\n",
            "Epoch 23/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8382 - accuracy: 0.6549 - val_loss: 1.0892 - val_accuracy: 0.5489\n",
            "Epoch 24/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8337 - accuracy: 0.6549 - val_loss: 1.0719 - val_accuracy: 0.5489\n",
            "Epoch 25/50\n",
            "23/23 [==============================] - 0s 3ms/step - loss: 0.8241 - accuracy: 0.6739 - val_loss: 1.0816 - val_accuracy: 0.5489\n",
            "Epoch 26/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8252 - accuracy: 0.6671 - val_loss: 1.0766 - val_accuracy: 0.5598\n",
            "Epoch 27/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.8139 - accuracy: 0.6644 - val_loss: 1.0924 - val_accuracy: 0.5435\n",
            "Epoch 28/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.8079 - accuracy: 0.6726 - val_loss: 1.0877 - val_accuracy: 0.5543\n",
            "Epoch 29/50\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7941 - accuracy: 0.6658 - val_loss: 1.0837 - val_accuracy: 0.5598\n",
            "Epoch 30/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7841 - accuracy: 0.6712 - val_loss: 1.1020 - val_accuracy: 0.5652\n",
            "Epoch 31/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7640 - accuracy: 0.6984 - val_loss: 1.1169 - val_accuracy: 0.5489\n",
            "Epoch 32/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7872 - accuracy: 0.6726 - val_loss: 1.0958 - val_accuracy: 0.5598\n",
            "Epoch 33/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7844 - accuracy: 0.6821 - val_loss: 1.0926 - val_accuracy: 0.5489\n",
            "Epoch 34/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7735 - accuracy: 0.6916 - val_loss: 1.1087 - val_accuracy: 0.5489\n",
            "Epoch 35/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7764 - accuracy: 0.6739 - val_loss: 1.0886 - val_accuracy: 0.5652\n",
            "Epoch 36/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7548 - accuracy: 0.6916 - val_loss: 1.1022 - val_accuracy: 0.5489\n",
            "Epoch 37/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7525 - accuracy: 0.7106 - val_loss: 1.0993 - val_accuracy: 0.5598\n",
            "Epoch 38/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7620 - accuracy: 0.6834 - val_loss: 1.1063 - val_accuracy: 0.5543\n",
            "Epoch 39/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7577 - accuracy: 0.6984 - val_loss: 1.1082 - val_accuracy: 0.5652\n",
            "Epoch 40/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7401 - accuracy: 0.7106 - val_loss: 1.1060 - val_accuracy: 0.5761\n",
            "Epoch 41/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7437 - accuracy: 0.6916 - val_loss: 1.1125 - val_accuracy: 0.5652\n",
            "Epoch 42/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7419 - accuracy: 0.6875 - val_loss: 1.1372 - val_accuracy: 0.5598\n",
            "Epoch 43/50\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 0.7509 - accuracy: 0.7052 - val_loss: 1.1315 - val_accuracy: 0.5543\n",
            "Epoch 44/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7344 - accuracy: 0.6943 - val_loss: 1.1321 - val_accuracy: 0.5598\n",
            "Epoch 45/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7161 - accuracy: 0.7052 - val_loss: 1.1242 - val_accuracy: 0.5707\n",
            "Epoch 46/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7087 - accuracy: 0.7215 - val_loss: 1.1408 - val_accuracy: 0.5707\n",
            "Epoch 47/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.6922 - accuracy: 0.7133 - val_loss: 1.1366 - val_accuracy: 0.5652\n",
            "Epoch 48/50\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 0.7049 - accuracy: 0.7079 - val_loss: 1.1379 - val_accuracy: 0.5652\n",
            "Epoch 49/50\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 0.7018 - accuracy: 0.7065 - val_loss: 1.1589 - val_accuracy: 0.5598\n",
            "Epoch 50/50\n",
            "23/23 [==============================] - 0s 4ms/step - loss: 0.7179 - accuracy: 0.7052 - val_loss: 1.1328 - val_accuracy: 0.5598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import LeakyReLU\n",
        "Dense(128, activation=LeakyReLU(alpha=0.1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lu2XUuRhyhvI",
        "outputId": "7af6adfd-2a79-444c-ec37-ae38804ad6b1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.dense.Dense at 0x7a61444d2510>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Activation"
      ],
      "metadata": {
        "id": "eoCZyqEvytlO"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Dense(128),\n",
        "BatchNormalization(),\n",
        "Activation('relu'),\n",
        "Dropout(0.2),"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv3sZyIHyjYE",
        "outputId": "914c1fe7-cae1-476c-b653-6517723a869c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<keras.src.layers.regularization.dropout.Dropout at 0x7a613a85bc50>,)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_multi), y=y_train_multi)\n",
        "class_weights = {i: class_weights[i] for i in range(len(class_weights))}"
      ],
      "metadata": {
        "id": "OyhqODCMylJ4"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Binary Model\n",
        "bin_loss, bin_acc = binary_model.evaluate(X_test_bin, y_test_bin)\n",
        "print(f\"Binary Classification Accuracy: {bin_acc*100:.2f}%\")\n",
        "\n",
        "# Evaluate Multi-Class Model\n",
        "multi_loss, multi_acc = multi_model.evaluate(X_test_multi, y_test_multi_encoded)\n",
        "print(f\"Multi-Class Classification Accuracy: {multi_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FAQovFIyM_H",
        "outputId": "87a8ddf5-66d1-4ff4-ce1a-dac87fe5fd3c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4059 - accuracy: 0.8370\n",
            "Binary Classification Accuracy: 83.70%\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 1.1328 - accuracy: 0.5598\n",
            "Multi-Class Classification Accuracy: 55.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "unique, counts = np.unique(y_train_multi, return_counts=True)\n",
        "print(dict(zip(unique, counts)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVGSN0QOyQn7",
        "outputId": "1f479c9a-a2f1-43c8-f823-199ab1d8d353"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 336, 1: 211, 2: 84, 3: 81, 4: 24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_multi = scaler.fit_transform(X_train_multi)\n",
        "X_test_multi = scaler.transform(X_test_multi)"
      ],
      "metadata": {
        "id": "mAGdDR_ey5kx"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_multi = tf.keras.Sequential([\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(5, activation=\"softmax\")  # Ensure correct output shape\n",
        "])\n"
      ],
      "metadata": {
        "id": "H_4RPGq7y7Ur"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_multi.compile(optimizer='adam',\n",
        "                    loss='sparse_categorical_crossentropy',\n",
        "                    metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "xYkd6uW4y9Jt"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                 factor=0.5,\n",
        "                                                 patience=3,\n",
        "                                                 min_lr=1e-5)"
      ],
      "metadata": {
        "id": "19ouW3cQzAgg"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Multi-Class Model\n",
        "multi_loss, multi_acc = multi_model.evaluate(X_test_multi, y_test_multi_encoded)\n",
        "print(f\"Multi-Class Classification Accuracy: {multi_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ohIZbHPzCGu",
        "outputId": "508eb8b9-024c-48d6-8ff4-62f392230be1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6/6 [==============================] - 0s 2ms/step - loss: 1.1328 - accuracy: 0.5598\n",
            "Multi-Class Classification Accuracy: 55.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(y_train_multi.shape) > 1:\n",
        "    y_train_multi = np.argmax(y_train_multi, axis=1)\n",
        "    y_test_multi = np.argmax(y_test_multi, axis=1)"
      ],
      "metadata": {
        "id": "lay2qE-pzF6P"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"y_train_multi shape: {y_train_multi.shape}\")\n",
        "print(f\"Unique labels: {np.unique(y_train_multi)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncc4qSG_zPnR",
        "outputId": "3a0e0ef5-0ce4-47b6-9c1d-25cd8733eb7f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train_multi shape: (736,)\n",
            "Unique labels: [0 1 2 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique, counts = np.unique(y_train_multi, return_counts=True)\n",
        "print(\"Class distribution:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WUxdzTYzRII",
        "outputId": "0faccf4b-f291-4951-b6d5-5f7841f609b6"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution: {0: 336, 1: 211, 2: 84, 3: 81, 4: 24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_train_multi), y=y_train_multi)\n",
        "class_weights = dict(enumerate(class_weights))\n"
      ],
      "metadata": {
        "id": "NXkIin6TzT8A"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model_multi.fit(\n",
        "    X_train_multi, y_train_multi,\n",
        "    validation_data=(X_test_multi, y_test_multi),  # Use validation data\n",
        "    epochs=200,\n",
        "    batch_size=64,\n",
        "    class_weight=class_weights,  # Class weights to handle imbalance\n",
        "    callbacks=[reduce_lr]  # Learning rate scheduler\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JrETUxRzViA",
        "outputId": "04654b67-654e-480e-b629-0991cee62423"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "12/12 [==============================] - 8s 54ms/step - loss: 2.3143 - accuracy: 0.2310 - val_loss: 1.5613 - val_accuracy: 0.2772 - lr: 0.0010\n",
            "Epoch 2/200\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.8348 - accuracy: 0.3370 - val_loss: 1.5150 - val_accuracy: 0.3696 - lr: 0.0010\n",
            "Epoch 3/200\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1.6755 - accuracy: 0.3967 - val_loss: 1.4835 - val_accuracy: 0.4130 - lr: 0.0010\n",
            "Epoch 4/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.6331 - accuracy: 0.4253 - val_loss: 1.4550 - val_accuracy: 0.4402 - lr: 0.0010\n",
            "Epoch 5/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.5337 - accuracy: 0.4293 - val_loss: 1.4308 - val_accuracy: 0.4348 - lr: 0.0010\n",
            "Epoch 6/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5254 - accuracy: 0.4565 - val_loss: 1.3981 - val_accuracy: 0.4402 - lr: 0.0010\n",
            "Epoch 7/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.3997 - accuracy: 0.4946 - val_loss: 1.3684 - val_accuracy: 0.4674 - lr: 0.0010\n",
            "Epoch 8/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3474 - accuracy: 0.5217 - val_loss: 1.3372 - val_accuracy: 0.4837 - lr: 0.0010\n",
            "Epoch 9/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.3425 - accuracy: 0.5014 - val_loss: 1.3018 - val_accuracy: 0.5109 - lr: 0.0010\n",
            "Epoch 10/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3392 - accuracy: 0.5163 - val_loss: 1.2747 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 11/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3560 - accuracy: 0.5340 - val_loss: 1.2627 - val_accuracy: 0.5217 - lr: 0.0010\n",
            "Epoch 12/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.2565 - accuracy: 0.5312 - val_loss: 1.2467 - val_accuracy: 0.5109 - lr: 0.0010\n",
            "Epoch 13/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1896 - accuracy: 0.5408 - val_loss: 1.2250 - val_accuracy: 0.4946 - lr: 0.0010\n",
            "Epoch 14/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.2221 - accuracy: 0.5217 - val_loss: 1.1975 - val_accuracy: 0.5054 - lr: 0.0010\n",
            "Epoch 15/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.2187 - accuracy: 0.5326 - val_loss: 1.1803 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 16/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0923 - accuracy: 0.5815 - val_loss: 1.1745 - val_accuracy: 0.4891 - lr: 0.0010\n",
            "Epoch 17/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1473 - accuracy: 0.5394 - val_loss: 1.1680 - val_accuracy: 0.4891 - lr: 0.0010\n",
            "Epoch 18/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2374 - accuracy: 0.5530 - val_loss: 1.1675 - val_accuracy: 0.4946 - lr: 0.0010\n",
            "Epoch 19/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1353 - accuracy: 0.5652 - val_loss: 1.1615 - val_accuracy: 0.4891 - lr: 0.0010\n",
            "Epoch 20/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0528 - accuracy: 0.5856 - val_loss: 1.1567 - val_accuracy: 0.5000 - lr: 0.0010\n",
            "Epoch 21/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0827 - accuracy: 0.5734 - val_loss: 1.1558 - val_accuracy: 0.5054 - lr: 0.0010\n",
            "Epoch 22/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1032 - accuracy: 0.5897 - val_loss: 1.1518 - val_accuracy: 0.5054 - lr: 0.0010\n",
            "Epoch 23/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0491 - accuracy: 0.5870 - val_loss: 1.1425 - val_accuracy: 0.5163 - lr: 0.0010\n",
            "Epoch 24/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0453 - accuracy: 0.5951 - val_loss: 1.1421 - val_accuracy: 0.5109 - lr: 0.0010\n",
            "Epoch 25/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0002 - accuracy: 0.6101 - val_loss: 1.1449 - val_accuracy: 0.5109 - lr: 0.0010\n",
            "Epoch 26/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9940 - accuracy: 0.6128 - val_loss: 1.1538 - val_accuracy: 0.5109 - lr: 0.0010\n",
            "Epoch 27/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9459 - accuracy: 0.6155 - val_loss: 1.1636 - val_accuracy: 0.5326 - lr: 0.0010\n",
            "Epoch 28/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9827 - accuracy: 0.6033 - val_loss: 1.1619 - val_accuracy: 0.5326 - lr: 5.0000e-04\n",
            "Epoch 29/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9413 - accuracy: 0.6209 - val_loss: 1.1608 - val_accuracy: 0.5380 - lr: 5.0000e-04\n",
            "Epoch 30/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9957 - accuracy: 0.6182 - val_loss: 1.1673 - val_accuracy: 0.5435 - lr: 5.0000e-04\n",
            "Epoch 31/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9609 - accuracy: 0.6413 - val_loss: 1.1711 - val_accuracy: 0.5380 - lr: 2.5000e-04\n",
            "Epoch 32/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9663 - accuracy: 0.6114 - val_loss: 1.1731 - val_accuracy: 0.5380 - lr: 2.5000e-04\n",
            "Epoch 33/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9407 - accuracy: 0.6291 - val_loss: 1.1768 - val_accuracy: 0.5326 - lr: 2.5000e-04\n",
            "Epoch 34/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9605 - accuracy: 0.6168 - val_loss: 1.1784 - val_accuracy: 0.5326 - lr: 1.2500e-04\n",
            "Epoch 35/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9627 - accuracy: 0.6087 - val_loss: 1.1806 - val_accuracy: 0.5380 - lr: 1.2500e-04\n",
            "Epoch 36/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9911 - accuracy: 0.6128 - val_loss: 1.1830 - val_accuracy: 0.5380 - lr: 1.2500e-04\n",
            "Epoch 37/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9769 - accuracy: 0.6155 - val_loss: 1.1868 - val_accuracy: 0.5326 - lr: 6.2500e-05\n",
            "Epoch 38/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9277 - accuracy: 0.6168 - val_loss: 1.1907 - val_accuracy: 0.5272 - lr: 6.2500e-05\n",
            "Epoch 39/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9526 - accuracy: 0.6264 - val_loss: 1.1947 - val_accuracy: 0.5272 - lr: 6.2500e-05\n",
            "Epoch 40/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9799 - accuracy: 0.6128 - val_loss: 1.1985 - val_accuracy: 0.5272 - lr: 3.1250e-05\n",
            "Epoch 41/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9147 - accuracy: 0.6440 - val_loss: 1.2012 - val_accuracy: 0.5272 - lr: 3.1250e-05\n",
            "Epoch 42/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8954 - accuracy: 0.6345 - val_loss: 1.2028 - val_accuracy: 0.5272 - lr: 3.1250e-05\n",
            "Epoch 43/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9308 - accuracy: 0.6399 - val_loss: 1.2042 - val_accuracy: 0.5272 - lr: 1.5625e-05\n",
            "Epoch 44/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9678 - accuracy: 0.6019 - val_loss: 1.2069 - val_accuracy: 0.5217 - lr: 1.5625e-05\n",
            "Epoch 45/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9635 - accuracy: 0.6209 - val_loss: 1.2096 - val_accuracy: 0.5217 - lr: 1.5625e-05\n",
            "Epoch 46/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9681 - accuracy: 0.6168 - val_loss: 1.2106 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 47/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9232 - accuracy: 0.6277 - val_loss: 1.2117 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 48/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9902 - accuracy: 0.5978 - val_loss: 1.2135 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 49/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9432 - accuracy: 0.6277 - val_loss: 1.2152 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 50/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9103 - accuracy: 0.6427 - val_loss: 1.2158 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 51/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9110 - accuracy: 0.6264 - val_loss: 1.2170 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 52/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9707 - accuracy: 0.6223 - val_loss: 1.2178 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 53/200\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.9642 - accuracy: 0.6060 - val_loss: 1.2191 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 54/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.0151 - accuracy: 0.6114 - val_loss: 1.2186 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 55/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9854 - accuracy: 0.5883 - val_loss: 1.2206 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 56/200\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.9419 - accuracy: 0.6141 - val_loss: 1.2214 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 57/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9400 - accuracy: 0.6359 - val_loss: 1.2216 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 58/200\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.9025 - accuracy: 0.6372 - val_loss: 1.2229 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 59/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9666 - accuracy: 0.6304 - val_loss: 1.2240 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 60/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9394 - accuracy: 0.6196 - val_loss: 1.2232 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 61/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9220 - accuracy: 0.6128 - val_loss: 1.2230 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 62/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9964 - accuracy: 0.5856 - val_loss: 1.2234 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 63/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9679 - accuracy: 0.6128 - val_loss: 1.2234 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 64/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9644 - accuracy: 0.6209 - val_loss: 1.2234 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 65/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9094 - accuracy: 0.6209 - val_loss: 1.2238 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 66/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9693 - accuracy: 0.6141 - val_loss: 1.2236 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 67/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8921 - accuracy: 0.6291 - val_loss: 1.2233 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 68/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9281 - accuracy: 0.6141 - val_loss: 1.2237 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 69/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9958 - accuracy: 0.6223 - val_loss: 1.2244 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 70/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9588 - accuracy: 0.6168 - val_loss: 1.2250 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 71/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9263 - accuracy: 0.6264 - val_loss: 1.2248 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 72/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9281 - accuracy: 0.6454 - val_loss: 1.2247 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 73/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9352 - accuracy: 0.6318 - val_loss: 1.2236 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 74/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9380 - accuracy: 0.6304 - val_loss: 1.2229 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 75/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9897 - accuracy: 0.6318 - val_loss: 1.2243 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 76/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9107 - accuracy: 0.6304 - val_loss: 1.2240 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 77/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9891 - accuracy: 0.6223 - val_loss: 1.2227 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 78/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9848 - accuracy: 0.6264 - val_loss: 1.2230 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 79/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8843 - accuracy: 0.6318 - val_loss: 1.2229 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 80/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9289 - accuracy: 0.6399 - val_loss: 1.2234 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 81/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9238 - accuracy: 0.6508 - val_loss: 1.2233 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 82/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9566 - accuracy: 0.6250 - val_loss: 1.2235 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 83/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9962 - accuracy: 0.6087 - val_loss: 1.2242 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 84/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.8974 - accuracy: 0.6209 - val_loss: 1.2237 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 85/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9709 - accuracy: 0.6060 - val_loss: 1.2236 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 86/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9175 - accuracy: 0.6372 - val_loss: 1.2232 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 87/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9149 - accuracy: 0.6467 - val_loss: 1.2238 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 88/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9860 - accuracy: 0.5978 - val_loss: 1.2240 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 89/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8902 - accuracy: 0.6386 - val_loss: 1.2245 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 90/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0386 - accuracy: 0.6209 - val_loss: 1.2244 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 91/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0572 - accuracy: 0.5856 - val_loss: 1.2246 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 92/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9175 - accuracy: 0.6318 - val_loss: 1.2238 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 93/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9626 - accuracy: 0.6359 - val_loss: 1.2245 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 94/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9449 - accuracy: 0.6386 - val_loss: 1.2254 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 95/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9141 - accuracy: 0.6209 - val_loss: 1.2252 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 96/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9499 - accuracy: 0.6304 - val_loss: 1.2240 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 97/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9008 - accuracy: 0.6236 - val_loss: 1.2235 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 98/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9382 - accuracy: 0.6427 - val_loss: 1.2226 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 99/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9854 - accuracy: 0.6101 - val_loss: 1.2222 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 100/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9183 - accuracy: 0.6005 - val_loss: 1.2228 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 101/200\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.8757 - accuracy: 0.6291 - val_loss: 1.2226 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 102/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9560 - accuracy: 0.6128 - val_loss: 1.2222 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 103/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9023 - accuracy: 0.6291 - val_loss: 1.2233 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 104/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9511 - accuracy: 0.6168 - val_loss: 1.2229 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 105/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9786 - accuracy: 0.6386 - val_loss: 1.2222 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 106/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8826 - accuracy: 0.6753 - val_loss: 1.2230 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 107/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9212 - accuracy: 0.6318 - val_loss: 1.2241 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 108/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9804 - accuracy: 0.6182 - val_loss: 1.2236 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 109/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9238 - accuracy: 0.6359 - val_loss: 1.2226 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 110/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9122 - accuracy: 0.6209 - val_loss: 1.2225 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 111/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9445 - accuracy: 0.6345 - val_loss: 1.2222 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 112/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8659 - accuracy: 0.6440 - val_loss: 1.2220 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 113/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8936 - accuracy: 0.6332 - val_loss: 1.2216 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 114/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9527 - accuracy: 0.6128 - val_loss: 1.2214 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 115/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9046 - accuracy: 0.6522 - val_loss: 1.2212 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 116/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9191 - accuracy: 0.6168 - val_loss: 1.2219 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 117/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9405 - accuracy: 0.6372 - val_loss: 1.2213 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 118/200\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.9926 - accuracy: 0.6250 - val_loss: 1.2210 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 119/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9501 - accuracy: 0.6223 - val_loss: 1.2206 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 120/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8979 - accuracy: 0.6440 - val_loss: 1.2210 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 121/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9791 - accuracy: 0.6060 - val_loss: 1.2214 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 122/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9869 - accuracy: 0.6345 - val_loss: 1.2224 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 123/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8892 - accuracy: 0.6399 - val_loss: 1.2228 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 124/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9029 - accuracy: 0.6318 - val_loss: 1.2226 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 125/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8697 - accuracy: 0.6576 - val_loss: 1.2229 - val_accuracy: 0.5163 - lr: 1.0000e-05\n",
            "Epoch 126/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9529 - accuracy: 0.6209 - val_loss: 1.2228 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 127/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8502 - accuracy: 0.6535 - val_loss: 1.2226 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 128/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8928 - accuracy: 0.6372 - val_loss: 1.2230 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 129/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9299 - accuracy: 0.6223 - val_loss: 1.2240 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 130/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9384 - accuracy: 0.6386 - val_loss: 1.2242 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 131/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9447 - accuracy: 0.6332 - val_loss: 1.2252 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 132/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9143 - accuracy: 0.6155 - val_loss: 1.2262 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 133/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9475 - accuracy: 0.6277 - val_loss: 1.2263 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 134/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9890 - accuracy: 0.6141 - val_loss: 1.2251 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 135/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9227 - accuracy: 0.6304 - val_loss: 1.2263 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 136/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9334 - accuracy: 0.6277 - val_loss: 1.2257 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 137/200\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.9382 - accuracy: 0.6535 - val_loss: 1.2267 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 138/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9218 - accuracy: 0.6196 - val_loss: 1.2270 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 139/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9422 - accuracy: 0.6223 - val_loss: 1.2268 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 140/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9449 - accuracy: 0.6236 - val_loss: 1.2259 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 141/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8957 - accuracy: 0.6332 - val_loss: 1.2265 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 142/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9418 - accuracy: 0.6209 - val_loss: 1.2268 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 143/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9923 - accuracy: 0.6155 - val_loss: 1.2277 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 144/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9390 - accuracy: 0.6155 - val_loss: 1.2266 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 145/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8856 - accuracy: 0.6495 - val_loss: 1.2269 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 146/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8989 - accuracy: 0.6332 - val_loss: 1.2255 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 147/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9430 - accuracy: 0.6223 - val_loss: 1.2256 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 148/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8555 - accuracy: 0.6590 - val_loss: 1.2262 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 149/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9526 - accuracy: 0.6168 - val_loss: 1.2253 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 150/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8915 - accuracy: 0.6196 - val_loss: 1.2254 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 151/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9275 - accuracy: 0.6291 - val_loss: 1.2259 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 152/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9172 - accuracy: 0.6196 - val_loss: 1.2262 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 153/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9401 - accuracy: 0.6372 - val_loss: 1.2265 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 154/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9138 - accuracy: 0.6413 - val_loss: 1.2268 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 155/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9229 - accuracy: 0.6155 - val_loss: 1.2268 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 156/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8839 - accuracy: 0.6304 - val_loss: 1.2257 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 157/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.8974 - accuracy: 0.6440 - val_loss: 1.2259 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 158/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9188 - accuracy: 0.6291 - val_loss: 1.2260 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 159/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9032 - accuracy: 0.6359 - val_loss: 1.2261 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 160/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9673 - accuracy: 0.6264 - val_loss: 1.2262 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 161/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9217 - accuracy: 0.6318 - val_loss: 1.2261 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 162/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8648 - accuracy: 0.6277 - val_loss: 1.2266 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 163/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8985 - accuracy: 0.6345 - val_loss: 1.2270 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 164/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9297 - accuracy: 0.6250 - val_loss: 1.2274 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 165/200\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.9151 - accuracy: 0.6345 - val_loss: 1.2283 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 166/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.9681 - accuracy: 0.6399 - val_loss: 1.2287 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 167/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9058 - accuracy: 0.6359 - val_loss: 1.2284 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 168/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8934 - accuracy: 0.6264 - val_loss: 1.2292 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 169/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.8973 - accuracy: 0.6454 - val_loss: 1.2291 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 170/200\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.8694 - accuracy: 0.6386 - val_loss: 1.2290 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 171/200\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.9430 - accuracy: 0.6196 - val_loss: 1.2272 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 172/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9295 - accuracy: 0.6304 - val_loss: 1.2282 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 173/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9639 - accuracy: 0.6209 - val_loss: 1.2274 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 174/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9460 - accuracy: 0.6318 - val_loss: 1.2278 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 175/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9303 - accuracy: 0.6250 - val_loss: 1.2277 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 176/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9579 - accuracy: 0.6359 - val_loss: 1.2273 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 177/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9472 - accuracy: 0.6440 - val_loss: 1.2274 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 178/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8992 - accuracy: 0.6345 - val_loss: 1.2268 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 179/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8839 - accuracy: 0.6562 - val_loss: 1.2269 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 180/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8860 - accuracy: 0.6332 - val_loss: 1.2275 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 181/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9514 - accuracy: 0.6576 - val_loss: 1.2286 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 182/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0138 - accuracy: 0.6141 - val_loss: 1.2283 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 183/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8862 - accuracy: 0.6304 - val_loss: 1.2276 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 184/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9406 - accuracy: 0.6386 - val_loss: 1.2288 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 185/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9423 - accuracy: 0.6101 - val_loss: 1.2278 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 186/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9698 - accuracy: 0.6236 - val_loss: 1.2278 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 187/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9193 - accuracy: 0.6467 - val_loss: 1.2289 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 188/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8712 - accuracy: 0.6508 - val_loss: 1.2281 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 189/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9082 - accuracy: 0.6671 - val_loss: 1.2282 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 190/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9465 - accuracy: 0.6359 - val_loss: 1.2290 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 191/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8739 - accuracy: 0.6576 - val_loss: 1.2290 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 192/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9321 - accuracy: 0.6386 - val_loss: 1.2292 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 193/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9104 - accuracy: 0.6345 - val_loss: 1.2290 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 194/200\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9176 - accuracy: 0.6223 - val_loss: 1.2288 - val_accuracy: 0.5217 - lr: 1.0000e-05\n",
            "Epoch 195/200\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.8724 - accuracy: 0.6671 - val_loss: 1.2277 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 196/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9534 - accuracy: 0.6304 - val_loss: 1.2271 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 197/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8853 - accuracy: 0.6359 - val_loss: 1.2275 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 198/200\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.9038 - accuracy: 0.6332 - val_loss: 1.2272 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 199/200\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9188 - accuracy: 0.6481 - val_loss: 1.2271 - val_accuracy: 0.5272 - lr: 1.0000e-05\n",
            "Epoch 200/200\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9096 - accuracy: 0.6535 - val_loss: 1.2276 - val_accuracy: 0.5272 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_multi = tf.keras.Sequential([\n",
        "    Dense(512, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Dense(256, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Dense(5, activation=\"softmax\")  # Multi-class\n",
        "])\n"
      ],
      "metadata": {
        "id": "KqfOPnyXzW6B"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)"
      ],
      "metadata": {
        "id": "euM81EhXzu4a"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                                 factor=0.5,\n",
        "                                                 patience=3,\n",
        "                                                 min_lr=1e-5)\n"
      ],
      "metadata": {
        "id": "w12Nv43ozw8x"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_multi.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',  # Use 'sparse_categorical_crossentropy' if labels are not one-hot encoded\n",
        "    metrics=['accuracy']\n",
        ")\n"
      ],
      "metadata": {
        "id": "p07cXwndzymL"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training accuracy & validation accuracy\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Accuracy Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_bin.history['accuracy'], label=\"Binary Classification\")\n",
        "plt.plot(history_multi.history['accuracy'], label=\"Multi-Class Classification\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.title(\"Binary vs Multi-Class: Accuracy Over Epochs\")\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_bin.history['loss'], label=\"Binary Classification\")\n",
        "plt.plot(history_multi.history['loss'], label=\"Multi-Class Classification\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Binary vs Multi-Class: Loss Over Epochs\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "IggeOvVyz-X_",
        "outputId": "406c6d20-9b7f-413b-f520-523f1407f411"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}